\relax 
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {II}Data Analysis}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-A}}Exploratory Data Analysis}{1}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Summary Statistics of Exam Scores\relax }}{1}{}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:exam_stats}{{I}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-B}}HeatMap}{1}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Take the Total feature in the data table to check whether the scores distribution of students in the final exam conforms to the Gaussian distribution\relax }}{1}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Heatmap containing all the features, showing the correlation between the features by means of the Pearson algorithm. The warmer the color, the higher the positive correlation, and the colder the color, the higher the negative correlation.\relax }}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-C}}Random Forest}{2}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The remaining 9 sets of features generate a histogram of the magnitude of the impact on the results\relax }}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-D}}Standardization}{2}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces A boxplot of the results obtained after standardizing the existing 8 sets of feature data\relax }}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {III}Dimensionality Reduction}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-A}}Explained Variance Ratio}{2}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces Explained Variance Ratio(EVR) and Cumulative Variance Ratio (CVR) by PCA Components\relax }}{2}{}\protected@file@percent }
\newlabel{tab:pca_variance}{{II}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-B}}Cumulative Variance Ratio}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-C}}Principal Component Analysis}{3}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Principal Component Analysis \(k=2\)\relax }}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-D}}tSNE}{3}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces tSNE is a nonlinear dimensionality reduction technique that maps high-dimensional data to low-dimensional space by preserving the similarity between data points, and pays more attention to preserving the local structure of the data, making it easier to represent clusters or groups in high-dimensional data in low-dimensional space.\relax }}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {IV}Conclusion}{3}{}\protected@file@percent }
\gdef \@abspage@last{3}
